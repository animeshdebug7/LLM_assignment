{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Qp1fNEnZcL-",
    "outputId": "99c1ae2c-7978-429e-9649-56fcd5566699",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "QltdZqVTK-UX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfKQX-M_69wX"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "e8c935c6f2b347a7932c18e2770b1d67",
      "b959e331a7054b979f92867f2ee1875c",
      "b0d4df8e41cd44e48b3d63256e115957",
      "a1798f3cd1cf415bbd16dcf7036e5f01",
      "c4934fbd663f4dd89ef6f85f78836213",
      "b60a663333d94d3b9afed6807ba94348",
      "fb183291ae3e48eb962206e27bbde0a8",
      "1221317ba5494fff86dc83b2c787b290",
      "bfe3edc1234c40ffbacd05d79abf763e",
      "71b27e517edf4ba9b08183aa4170eba9",
      "d360825c49ef493e8fda3f973d25911a",
      "f42bf1af6c6349158eac8c61374c07ef",
      "7c1a8c14cf95483baaf5b8fb1ef09cf4",
      "98781ad4b6da464c818c1d1827717859",
      "850437a0cd754ffaa1758ca74d3a0d48",
      "948614f759644184b0a961b1779c0c7d",
      "0c172cb9c2904880b082a3a33b24b38f",
      "357a4701827f4ec9b1a3bebb3bd020a1",
      "90f11f7b53ff48f6ad623456654c1e87",
      "1e9f0626e258442d90d88d8c6c1acc10",
      "fac2354d1a074bee8bd67cf66bff31f8",
      "1ee0155931074f53befc0357eecf4b0f",
      "8faf42a0e9354a52afdd128d603a1355",
      "579d73626f744812b8d8d220564526cd",
      "0caa6d9a372d4ebb81670edde73d6a9f",
      "d2966737dece45e6a7d35492c378a143",
      "044755f82cbc421989e89e9f3ff0203f",
      "52b4cecd7d014302a42cad29186b7da4",
      "d1cff87a830244cfbb17fae99b3b410b",
      "c86a331eeeb54d4086cf9ac039292472",
      "ea86bb9864e14268ac0874bf14d40571",
      "d4c81178839f426c8093e79278313959",
      "a649d7bce49044c4b45d96dc1b0ff7b8",
      "8a5c38760544489087d3759fe780f07b",
      "66a0b1ebed4047ada4fc62e3bc07e022",
      "a10924597d474337aabd8f6b81449d41",
      "7304ba5d6e4a4681900662d920e40dcc",
      "e903db9bb6df4e70aa202e5ee7b436e1",
      "e4761170eadb4b6b9eb4df6a39a832a4",
      "ac01b2408b2e444a86c18767f34ce59a",
      "2d2fab010e304636a7fa3922c04da2b4",
      "2d099b54a78745c797d489702dc00fed",
      "a004273b814045e5b08935fa98029365",
      "abaf2294bee1474297ee5e73573cbb32",
      "a84e09aa86334b30ba7c06d3fe4c18b7",
      "3ed96f02fc434e08867015a70f4cf508",
      "cecc7db3b63e41778713c5a340c94c1a",
      "500bd8e688fe4bfd9921b371d0d77018",
      "a099733e17d641f4a98bf42e9f760cf8",
      "ca1877178afc478fb06f540684d79517",
      "553e679937d8481d92009067d4a0c4e5",
      "a92efa7756d442cdab28f6df98f8f799",
      "d04787306d1a4f10b1e98adb7bb744fb",
      "5df6c2718b704ee8a645c5ae98f1d275",
      "64cd89277be240f880108556ac5c0259",
      "ae209e4b61014555b458975adadbb218",
      "bced7abd9dd24c81b4d06f26428f34cb",
      "66998225a2014b4281ee71695d2cedb7",
      "7a3d47886e144e36a1e1d9d43de78570",
      "dad82b90289b44848473b756b4b6e1d3",
      "3203b66aae9d455891f7e7a0302f20c6",
      "9871cb645c984da3bfb81c207a3b7a1f",
      "c2f4fdf7bac04322a8be99a6973ab5ee",
      "44ac1204ed0740dbb9a10b1fd9cdc989",
      "b1b9a3564bed4d329cf1768d95cf3a25",
      "dd5509b389d34ad588080b352bb3a947",
      "a9bebc4f97434c4d843049a89a4daf41",
      "0b14a0a9f6e745a582e8250605433807",
      "d830d0c15b3140c3be6e80f78e8e4504",
      "7b97d30e20634b0489251db8201c9c5a",
      "c185a065217140f2a42fb27a12ca55bb",
      "251434b02fa149d3919e39da4f3867b0",
      "12a1c9518e97497b8294b2838ffc5a5e",
      "5fb5e456122e4e38ab423290c50921f1",
      "c9b9614c44d34382b170093710cafc23",
      "29a4e1deaf9642e6afbce293875bd2de",
      "cd2110d849e847c89a3baca5234833e7"
     ]
    },
    "id": "f3KzdKbZ6-kJ",
    "outputId": "35dd9dae-80e7-4cff-8046-04da962ed6e2"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders, processors\n",
    "\n",
    "train_data, validation_data = load_dataset(\"roneneldan/TinyStories\", split = ['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Once there was a little girl called Lucy who wanted to sell something very special. She carefully wrapped up her knee in a box and took it outside.\\n\\nOnce she got to the market place, Lucy could see the many different people gathered together and she felt shy. She began to shout, â€œIâ€™m selling my knee!â€\\n\\nOne of the people at the market was an old woman who had seen many things in her life. She approached Lucy and said, â€œDo you want some help selling your knee?â€\\n\\nLucy nodded and smiled. The old woman was very compassionate and kind and she soon found a buyer who was willing to pay a good amount of money for Lucy's knee. Lucy could not believe her luck!\\n\\nThe old woman then said, â€œYou should always be brave and use your compassion when trying to sell something. You never know who might be in the market place and be willing to buy it.â€\\n\\nLucy smiled and said, â€œThank you so much for your advice and for helping me to sell my knee.â€\\n\\nThe old woman smiled back at her and said, â€œIt was my pleasure. I'm sure you'll have success in other things you try and sell in the future.â€\\n\\nAnd Lucy never forgot the old woman's words or the lesson she had learnt on that day.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'][115]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\n",
      "\n",
      "Lily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\n",
      "\n",
      "Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.\n"
     ]
    }
   ],
   "source": [
    "for i in train_data:\n",
    "    print(i['text'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerc(x):\n",
    "    return {\"text\": x[\"text\"].lower()}\n",
    "\n",
    "train_data = train_data.map(lowerc)\n",
    "validation_data = validation_data.map(lowerc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def punc(data):\n",
    "    return {'text' : re.sub(r\"[^A-Za-z\\s:]\", \"\", data['text'])}\n",
    "\n",
    "train_data = train_data.map(punc)\n",
    "validation_data = validation_data.map(punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/animeshsingh/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "def nltk_tokenize(example):\n",
    "    return {\"tokens\": word_tokenize(example[\"text\"])}\n",
    "\n",
    "tok_train_data = train_data.map(nltk_tokenize)\n",
    "tok_val_data = validation_data.map(nltk_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'tokens'],\n",
       "    num_rows: 2119719\n",
       "})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['once', 'upon', 'a', 'time', 'there']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_val_data['tokens'][115][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import contractions\n",
    "# def cont(data):\n",
    "#     return {'text' : contractions.fix(data['text'])}\n",
    "\n",
    "# train_data = train_data.map(cont)\n",
    "# validation_data = validation_data.map(cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fasttext Word level tok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "# fst_model = fasttext.train_unsupervised('tok_train_txt.txt', model = 'skipgram', dim = 300, thread = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tok_train_txt.txt', 'w', encoding = 'utf-8') as f:\n",
    "    for tokens in tok_train_data['tokens']:\n",
    "        if not tokens:\n",
    "            continue\n",
    "        if isinstance(tokens, list):\n",
    "            tokens = ['<sos>'] + tokens + ['<eos>'] # Manually added <eos> and <sos>\n",
    "            f.write(' '.join(map(str, tokens)) + '\\n')\n",
    "        else:\n",
    "            f.write(str(tokens).strip() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fst_model.save_model(\"fst_fntnd.bin\")\n",
    "fst_model = fasttext.load_model(\"/Users/animeshsingh/Desktop/Models/fst_fntnd.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fst_dim = fst_model.get_dimension()\n",
    "fst_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(tokenizer_vocab, fst_model, embedding_dim):\n",
    "    vocab_size = len(tokenizer_vocab)\n",
    "    embeddings = torch.zeros(vocab_size, embedding_dim)\n",
    "    \n",
    "    found = 0\n",
    "    for token, idx in tokenizer_vocab.items():\n",
    "        try:\n",
    "            embeddings[idx] = torch.FloatTensor(fst_model.wv[token])\n",
    "            found += 1\n",
    "        except KeyError:\n",
    "            embeddings[idx] = torch.randn(embedding_dim) * 0.1 #for new oov vectors\n",
    "    \n",
    "    print(f\"Found {found}/{vocab_size} tokens in FastText model\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "vector = fst_model.get_sentence_vector('i will get full marks')\n",
    "print(vector.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/Users/animeshsingh/Desktop/Models/tok_train_txt.txt\", \"r\", encoding = \"utf-8\") as f:\n",
    "#     lines = [line.strip().split() for line in f.readlines() if line.strip()]\n",
    "\n",
    "lines = []\n",
    "with open(\"/Users/animeshsingh/Desktop/tok_train_txt_small.txt\", \"r\", encoding = \"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            lines.append(line.split())\n",
    "\n",
    "dim = (300,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Very slow, Didn't use!\n",
    "\n",
    "# sequences = []\n",
    "# for words in lines:\n",
    "#     vectors = [fst_model.get_word_vector(i) for i in words]\n",
    "#     seq_tensor = torch.tensor(vectors, dtype = torch.float32)\n",
    "#     sequences.append(seq_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "# dim = fst_model.get_dimension()\n",
    "# for seq in lines:\n",
    "#     T = len(seq)\n",
    "#     if T == 0:\n",
    "#         continue\n",
    "#     buf = np.empty((T, dim), dtype = np.float32)\n",
    "#     for i, w in enumerate(seq):\n",
    "#         buf[i, :] = fst_model.get_word_vector(w)\n",
    "#     sequences.append(torch.from_numpy(buf))\n",
    "\n",
    "def load_lines(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                yield line.split()\n",
    "                \n",
    "for tokens in load_lines(\"/Users/animeshsingh/Desktop/tok_train_txt_small.txt\"):\n",
    "    vectors = [fst_model.get_word_vector(i) for i in tokens]\n",
    "    seq_tensor = torch.tensor(vectors, dtype = torch.float32)\n",
    "    sequences.append(seq_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding (with 0s and not appending \"pad\" to the vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "padded = []\n",
    "def paddy(x):\n",
    "    padded = pad_sequence(\n",
    "        [torch.tensor(seq) for seq in x],\n",
    "        batch_first = True, padding_value=0\n",
    "    )\n",
    "    return padded\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0w/13hqjsqx09vggh9kcnbrp62w0000gn/T/ipykernel_17485/3448172882.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  [torch.tensor(seq) for seq in x],\n"
     ]
    }
   ],
   "source": [
    "padded_train = paddy(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### FastText Embedding using Gensim (Did not use in the final model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import load_facebook_model\n",
    "\n",
    "model = load_facebook_model(r\"D:\\cc.en.300.bin\")\n",
    "\n",
    "print(model.wv[\"apple\"][:10])      # first 10 dimensions\n",
    "print(model.vector_size)           # 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de0ef8e27fe4932986d47006bb17321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 300)\n"
     ]
    }
   ],
   "source": [
    "def add_embeddings(data):\n",
    "    vectors = [model.wv.get_vector(tok).astype(np.float32)\n",
    "               if tok in model.wv.key_to_index\n",
    "               else np.zeros(model.vector_size, dtype = np.float32)\n",
    "               for tok in data[\"tokens\"]]\n",
    "    data[\"embeddings\"] = vectors\n",
    "    return data\n",
    "\n",
    "emb_train_data = tok_val_data.map(add_embeddings)\n",
    "print(np.array(emb_train_data[0][\"embeddings\"]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pos Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math\n",
    "\n",
    "def pos_enc(seq_len = 250, dim = 300):\n",
    "    pos = torch.arange(seq_len).unsqueeze(1).float()\n",
    "    denom = torch.pow(10000, (-torch.arange(0, dim, 2).float() / dim))\n",
    "    posenc = torch.zeros(seq_len, dim)\n",
    "    posenc[:, 0::2] = torch.sin(pos / denom)\n",
    "    posenc[:, 1::2] = torch.cos(pos / denom)\n",
    "    return posenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "posenc = pos_enc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([250, 300])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posenc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_emb(x):\n",
    "    tokens = x.split()\n",
    "    seq_len = len(tokens)\n",
    "    embeddings = [fst_model.get_word_vector(t) for t in tokens]\n",
    "    embeddings = np.stack(embeddings)\n",
    "    return posenc[:seq_len, :] + embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0w/13hqjsqx09vggh9kcnbrp62w0000gn/T/ipykernel_8787/3478609880.py:6: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  return posenc[:seq_len, :] + embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1332,  1.0258, -0.0253,  ...,  1.0522, -0.0031,  0.8893],\n",
       "        [ 0.7767,  0.5119,  1.0907,  ..., -0.5351, -0.8957, -0.1369],\n",
       "        [ 1.0022, -0.3728,  1.0061,  ..., -0.1493, -0.0532, -0.9673],\n",
       "        ...,\n",
       "        [-1.0829,  0.4869, -0.9610,  ...,  1.0307, -0.5332,  0.3246],\n",
       "        [-0.6165,  1.1678,  0.1792,  ...,  0.2780, -0.3805, -0.8971],\n",
       "        [ 0.9023,  0.6785,  1.1042,  ..., -0.9052,  0.6768, -0.5415]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = final_emb('i am going on a trip this winter')\n",
    "emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layernorm(x, dim = 300):\n",
    "    gamma = torch.ones(d_model)\n",
    "    beta = torch.zeros(d_model)\n",
    "    mean = torch.mean(x)\n",
    "    std = torch.std(x)\n",
    "    lnorm = (gamma * (x - mean) / (std + 0.00001)) + beta\n",
    "    return lnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder and Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "# from gensim.models import FastText\n",
    "import fasttext\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from evaluate import load\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK WordPiece tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLTKTokenizer:\n",
    "    def __init__(self, texts, max_vocab_size=50000):\n",
    "        \"\"\"Word-level tokenizer using NLTK\"\"\"\n",
    "        self.pad_token = '<pad>'\n",
    "        self.sos_token = '<sos>'\n",
    "        self.eos_token = '<eos>'\n",
    "        self.unk_token = '<unk>'\n",
    "        \n",
    "        # Build vocab\n",
    "        word_counts = Counter()\n",
    "        for text in tqdm(texts, desc=\"Building vocab\"):\n",
    "            tokens = word_tokenize(text.lower())\n",
    "            word_counts.update(tokens)\n",
    "        \n",
    "        self.token2idx = {\n",
    "            self.pad_token: 0,\n",
    "            self.sos_token: 1,\n",
    "            self.eos_token: 2,\n",
    "            self.unk_token: 3\n",
    "        }\n",
    "        \n",
    "        for word, _ in word_counts.most_common(max_vocab_size - 4):\n",
    "            self.token2idx[word] = len(self.token2idx)\n",
    "        \n",
    "        self.idx2token = {v: k for k, v in self.token2idx.items()}\n",
    "        self.vocab_size = len(self.token2idx)\n",
    "    \n",
    "    def encode(self, text):\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        return [self.token2idx.get(t, self.token2idx[self.unk_token]) for t in tokens]\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        return ' '.join([self.idx2token.get(i, self.unk_token) for i in ids])\n",
    "    \n",
    "    def get_vocab(self):\n",
    "        return self.token2idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loader with tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyStoriesDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, tokenizer, max_len=64):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.data = []\n",
    "        \n",
    "        for item in tqdm(hf_dataset, desc = \"Processing dataset\"):\n",
    "            text = item['text']\n",
    "            ids = tokenizer.encode(text)\n",
    "            ids = [tokenizer.token2idx[tokenizer.sos_token]] + ids + [tokenizer.token2idx[tokenizer.eos_token]]\n",
    "            \n",
    "            if len(ids) <= max_len:\n",
    "                self.data.append(ids)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ids = self.data[idx]\n",
    "        padded = ids + [self.tokenizer.token2idx[self.tokenizer.pad_token]] * (self.max_len - len(ids))\n",
    "        return torch.LongTensor(padded[:self.max_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(dim))\n",
    "        self.beta = nn.Parameter(torch.zeros(dim))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MHA with KV-Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, mask=None, cache=None):\n",
    "        B, T, C = x.shape\n",
    "        \n",
    "        Q = self.W_q(x).view(B, T, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(x).view(B, T, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(x).view(B, T, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # KV caching\n",
    "        if cache is not None:\n",
    "            if cache['k'] is not None:\n",
    "                K = torch.cat([cache['k'], K], dim=2)\n",
    "                V = torch.cat([cache['v'], V], dim=2)\n",
    "            cache['k'] = K\n",
    "            cache['v'] = V\n",
    "        \n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        attn_weights = attn.clone()\n",
    "        attn = self.dropout(attn)\n",
    "        \n",
    "        out = torch.matmul(attn, V)\n",
    "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        out = self.W_o(out)\n",
    "        \n",
    "        return out, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.dropout(F.gelu(self.fc1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, n_heads, dropout)\n",
    "        self.ff = FFN(d_model, d_ff, dropout)\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, mask = None, cache = None):\n",
    "        attn_out, attn_weights = self.attn(self.norm1(x), mask, cache)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        ff_out = self.ff(self.norm2(x))\n",
    "        x = x + self.dropout(ff_out)\n",
    "        return x, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer with Beam Search Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decod(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=300, n_layers=3, n_heads=6, \n",
    "                 d_ff=None, max_len=64, dropout=0.1, pretrained_embeddings=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "        \n",
    "        self.pos_encoding = SinusoidalPositionalEncoding(d_model, max_len)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, n_heads, d_ff, dropout)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.norm = LayerNorm(d_model)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "    \n",
    "    def create_causal_mask(self, seq_len, device):\n",
    "        mask = torch.tril(torch.ones(seq_len, seq_len, device=device))\n",
    "        return mask.view(1, 1, seq_len, seq_len)\n",
    "    \n",
    "    def forward(self, x, cache=None):\n",
    "        B, T = x.shape\n",
    "        device = x.device\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        mask = self.create_causal_mask(T, device)\n",
    "        \n",
    "        attn_weights_list = []\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            layer_cache = cache[i] if cache else None\n",
    "            x, attn_weights = layer(x, mask, layer_cache)\n",
    "            attn_weights_list.append(attn_weights)\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        logits = self.fc_out(x)\n",
    "        \n",
    "        return logits, attn_weights_list\n",
    "    \n",
    "    def generate(self, prompt_ids, tokenizer, max_len = 100, temperature = 1.0, \n",
    "                 top_k = 50, use_kv_cache = True):\n",
    "        # Stochastic sampling generation\n",
    "        self.eval()\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        generated = prompt_ids.copy()\n",
    "        x = torch.LongTensor([generated]).to(device)\n",
    "        \n",
    "        cache = None\n",
    "        if use_kv_cache:\n",
    "            cache = [{'k': None, 'v': None} for _ in self.layers]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_len):\n",
    "                if use_kv_cache and cache[0]['k'] is not None:\n",
    "                    logits, _ = self.forward(x[:, -1:], cache)\n",
    "                else:\n",
    "                    logits, _ = self.forward(x, cache)\n",
    "                \n",
    "                logits = logits[:, -1, :] / temperature\n",
    "                \n",
    "                if top_k > 0:\n",
    "                    top_k_logits, top_k_indices = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                    probs = F.softmax(top_k_logits, dim = -1)\n",
    "                    next_token_idx = torch.multinomial(probs, 1)\n",
    "                    next_token = top_k_indices.gather(-1, next_token_idx)\n",
    "                else:\n",
    "                    probs = F.softmax(logits, dim = -1)\n",
    "                    next_token = torch.multinomial(probs, 1)\n",
    "                \n",
    "                generated.append(next_token.item())\n",
    "                \n",
    "                if next_token.item() == tokenizer.token2idx[tokenizer.eos_token]:\n",
    "                    break\n",
    "                \n",
    "                x = torch.cat([x, next_token], dim = 1)\n",
    "        \n",
    "        return generated\n",
    "    \n",
    "    def beam_search(self, prompt_ids, tokenizer, max_len=50, beam_width=5):\n",
    "        \"\"\"Beam search decoding\"\"\"\n",
    "        self.eval()\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        beams = [(prompt_ids, 0.0)]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_len):\n",
    "                candidates = []\n",
    "                \n",
    "                for seq, score in beams:\n",
    "                    if seq[-1] == tokenizer.token2idx[tokenizer.eos_token]:\n",
    "                        candidates.append((seq, score))\n",
    "                        continue\n",
    "                    \n",
    "                    x = torch.LongTensor([seq]).to(device)\n",
    "                    logits, _ = self.forward(x)\n",
    "                    log_probs = F.log_softmax(logits[:, -1, :], dim=-1)\n",
    "                    \n",
    "                    top_log_probs, top_indices = torch.topk(log_probs, beam_width)\n",
    "                    \n",
    "                    for log_prob, idx in zip(top_log_probs[0], top_indices[0]):\n",
    "                        new_seq = seq + [idx.item()]\n",
    "                        new_score = score + log_prob.item()\n",
    "                        candidates.append((new_seq, new_score))\n",
    "                \n",
    "                beams = sorted(candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "                \n",
    "                if all(seq[-1] == tokenizer.token2idx[tokenizer.eos_token] for seq, _ in beams):\n",
    "                    break\n",
    "        \n",
    "        return beams[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training function with Grad. Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, device, grad_accum_steps=1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(tqdm(dataloader, desc=\"Training\")):\n",
    "        batch = batch.to(device)\n",
    "        x = batch[:, :-1]\n",
    "        y = batch[:, 1:]\n",
    "        \n",
    "        logits, _ = model(x)\n",
    "        loss = F.cross_entropy(\n",
    "            logits.reshape(-1, logits.size(-1)),\n",
    "            y.reshape(-1),\n",
    "            ignore_index=0\n",
    "        )\n",
    "        \n",
    "        (loss / grad_accum_steps).backward()\n",
    "        \n",
    "        if (batch_idx + 1) % grad_accum_steps == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            batch = batch.to(device)\n",
    "            x = batch[:, :-1]\n",
    "            y = batch[:, 1:]\n",
    "            \n",
    "            logits, _ = model(x)\n",
    "            loss = F.cross_entropy(\n",
    "                logits.reshape(-1, logits.size(-1)),\n",
    "                y.reshape(-1),\n",
    "                ignore_index=0\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity_bleu(model, tokenizer, val_dataset, device, n_samples=50):\n",
    "    \"\"\"Compute average perplexity and BLEU score\"\"\"\n",
    "    bleu_metric = load(\"bleu\")\n",
    "    \n",
    "    total_ppl = 0\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(min(n_samples, len(val_dataset))):\n",
    "        text = val_dataset[i]['text']\n",
    "        tokens = tokenizer.encode(text)\n",
    "        \n",
    "        if len(tokens) < 10:\n",
    "            continue\n",
    "        \n",
    "        # Use first 5 tokens as prompt\n",
    "        prompt_ids = [tokenizer.token2idx[tokenizer.sos_token]] + tokens[:5]\n",
    "        ground_truth = tokens[5:]\n",
    "        \n",
    "        # Generate continuation\n",
    "        generated_ids = model.generate(prompt_ids, tokenizer, max_len=len(ground_truth))\n",
    "        \n",
    "        # Remove special tokens\n",
    "        gen_tokens = [t for t in generated_ids if t not in [0, 1, 2, 3]]\n",
    "        \n",
    "        # Compute perplexity\n",
    "        x = torch.LongTensor([prompt_ids + ground_truth]).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits, _ = model(x[:, :-1])\n",
    "            loss = F.cross_entropy(\n",
    "                logits.reshape(-1, logits.size(-1)),\n",
    "                x[:, 1:].reshape(-1),\n",
    "                ignore_index=0\n",
    "            )\n",
    "            ppl = torch.exp(loss).item()\n",
    "            total_ppl += ppl\n",
    "        \n",
    "        # For BLEU\n",
    "        pred_text = tokenizer.decode(gen_tokens)\n",
    "        ref_text = tokenizer.decode(ground_truth)\n",
    "        predictions.append(pred_text)\n",
    "        references.append([ref_text])\n",
    "    \n",
    "    avg_ppl = total_ppl / n_samples\n",
    "    bleu_score = bleu_metric.compute(predictions=predictions, references=references)\n",
    "    \n",
    "    return avg_ppl, bleu_score['bleu']\n",
    "\n",
    "def visualize_attention(model, tokenizer, text, device, layer_idx=0):\n",
    "    \"\"\"Visualize attention patterns\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_ids = [tokenizer.token2idx[tokenizer.sos_token]] + tokens[:15]\n",
    "    x = torch.LongTensor([token_ids]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits, attn_weights = model(x)\n",
    "    \n",
    "    # Get attention from specified layer\n",
    "    attn = attn_weights[layer_idx][0].cpu().numpy()  # [n_heads, seq_len, seq_len]\n",
    "    \n",
    "    # Plot each head\n",
    "    n_heads = attn.shape[0]\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    \n",
    "    for head_idx in range(n_heads):\n",
    "        ax = axes[head_idx // 4, head_idx % 4]\n",
    "        sns.heatmap(attn[head_idx], ax=ax, cmap='viridis', cbar=True)\n",
    "        ax.set_title(f'Head {head_idx + 1}')\n",
    "        ax.set_xlabel('Key')\n",
    "        ax.set_ylabel('Query')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'max_len': 100,\n",
    "        'n_layers': 3,\n",
    "        'n_heads': 6,\n",
    "        'd_ff': 1200,\n",
    "        'dropout': 0.1,\n",
    "        'batch_size': 64,\n",
    "        'lr': 3e-4,\n",
    "        'n_epochs': 2,\n",
    "        'grad_accum_steps': 2,\n",
    "        'max_vocab_size': 50000\n",
    "    }\n",
    "    \n",
    "    # Load TinyStories dataset\n",
    "    print(\"Loading TinyStories dataset...\")\n",
    "    train_data = load_dataset(\"roneneldan/TinyStories\", split = 'train[:1%]')\n",
    "    val_data = load_dataset(\"roneneldan/TinyStories\", split = 'validation[:20%]')\n",
    "    # Sample for testing (remove for full training)\n",
    "    # train_data = dataset  # Use full dataset\n",
    "    # val_data = dataset['validation']\n",
    "    \n",
    "    # Extract texts\n",
    "    train_texts = [item['text'] for item in train_data]\n",
    "    \n",
    "    # Initialize NLTK tokenizer\n",
    "    print(\"Building NLTK tokenizer...\")\n",
    "    tokenizer = NLTKTokenizer(train_texts, max_vocab_size=config['max_vocab_size'])\n",
    "    print(f\"Vocabulary size: {tokenizer.vocab_size}\")\n",
    "    \n",
    "    # Load fine-tuned FastText\n",
    "    print(\"Loading fine-tuned FastText...\")\n",
    "    fst_model = fasttext.load_model(\"/Users/animeshsingh/Desktop/Models/fst_fntnd.bin\")\n",
    "    embedding_dim = fst_model.get_dimension()\n",
    "    print(f\"Embedding dimension: {embedding_dim}\")\n",
    "    \n",
    "    # Create embedding matrix\n",
    "    print(\"Creating embedding matrix...\")\n",
    "    embeddings = torch.zeros(tokenizer.vocab_size, embedding_dim)\n",
    "    found = 0\n",
    "    for token, idx in tokenizer.get_vocab().items():\n",
    "        try:\n",
    "            embeddings[idx] = torch.FloatTensor(fst_model.get_word_vector(token))\n",
    "            found += 1\n",
    "        except KeyError:\n",
    "            embeddings[idx] = torch.randn(embedding_dim) * 0.1\n",
    "    print(f\"Found {found}/{tokenizer.vocab_size} tokens in FastText\")\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"Creating datasets...\")\n",
    "    train_data = TinyStoriesDataset(train_data, tokenizer, config['max_len'])\n",
    "    val_data = TinyStoriesDataset(val_data, tokenizer, config['max_len'])\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size = config['batch_size'], shuffle = True)\n",
    "    val_loader = DataLoader(val_data, batch_size = config['batch_size'], shuffle = False)\n",
    "    \n",
    "    # Initialize model\n",
    "    device = 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model = decod(\n",
    "        vocab_size = tokenizer.vocab_size,\n",
    "        d_model = embedding_dim,\n",
    "        n_layers = config['n_layers'],\n",
    "        n_heads = config['n_heads'],\n",
    "        d_ff = config['d_ff'],\n",
    "        max_len = config['max_len'],\n",
    "        dropout = config['dropout'],\n",
    "        pretrained_embeddings = embeddings\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = config['lr'])\n",
    "    \n",
    "    # Training loop\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    perplexities = []\n",
    "    \n",
    "    for epoch in range(config['n_epochs']):\n",
    "        print(f\"\\nEpoch {epoch+1}/{config['n_epochs']}\")\n",
    "        \n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device, config['grad_accum_steps'])\n",
    "        val_loss = evaluate(model, val_loader, device)\n",
    "        \n",
    "        train_ppl = math.exp(train_loss)\n",
    "        val_ppl = math.exp(val_loss)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        perplexities.append(val_ppl)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train PPL: {train_ppl:.2f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val PPL: {val_ppl:.2f}\")\n",
    "        \n",
    "        # Sample generation\n",
    "        prompt = \"Once upon a time\"\n",
    "        prompt_ids = [tokenizer.token2idx[tokenizer.sos_token]] + tokenizer.encode(prompt)\n",
    "        generated_ids = model.generate(prompt_ids, tokenizer, max_len=30)\n",
    "        generated_text = tokenizer.decode(generated_ids)\n",
    "        print(f\"Generated: {generated_text}\")\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), 'decoder_transformer.pt')\n",
    "    print(\"\\nModel saved!\")\n",
    "    \n",
    "    # Evaluation\n",
    "    print(\"\\nEvaluating on validation set...\")\n",
    "    avg_ppl, bleu_score = compute_perplexity_bleu(model, tokenizer, val_data, device, n_samples = 50)\n",
    "    print(f\"Average Perplexity: {avg_ppl:.2f}\")\n",
    "    print(f\"Average BLEU Score: {bleu_score:.4f}\")\n",
    "    \n",
    "    # Visualize attention\n",
    "    sample_text = val_data[0]['text']\n",
    "    fig = visualize_attention(model, tokenizer, sample_text, device, layer_idx = 0)\n",
    "    plt.savefig('attention_visualization.png')\n",
    "    print(\"Attention visualization saved!\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(perplexities)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Perplexity')\n",
    "    plt.title('Validation Perplexity')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    # Beam search comparison\n",
    "    prompts = [\"Once upon\", \"The little\", \"In the\"]\n",
    "    for prompt in prompts:\n",
    "        prompt_ids = [tokenizer.token2idx[tokenizer.sos_token]] + tokenizer.encode(prompt)\n",
    "        \n",
    "        # Sampling\n",
    "        gen_sampling = model.generate(prompt_ids, tokenizer, max_len=20)\n",
    "        \n",
    "        # Beam search k=5\n",
    "        gen_beam = model.beam_search(prompt_ids, tokenizer, max_len=20, beam_width=5)\n",
    "        \n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        print(f\"Sampling: {tokenizer.decode(gen_sampling)}\")\n",
    "        print(f\"Beam Search: {tokenizer.decode(gen_beam)}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves.png')\n",
    "    print(\"Training curves saved!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Loading Finetuned fasttext \".bin\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_fasttext_bin(bin_path):\n",
    "    # \"\"\"Load FastText .bin file\"\"\"\n",
    "    # try:\n",
    "    #     # Try gensim\n",
    "    #     from gensim.models.fasttext import load_facebook_model\n",
    "    #     model = load_facebook_model(bin_path)\n",
    "    #     return model.wv\n",
    "    # except:\n",
    "        # Try native fasttext\n",
    "        import fasttext\n",
    "        model = fasttext.load_model('/Users/animeshsingh/Desktop/Models/fst_fntnd.bin')\n",
    "        return model\n",
    "\n",
    "def get_embedding(fst_model, word):\n",
    "    try:\n",
    "        ft_model.get_word_vector(word)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SimpleTokenizer:\n",
    "    def __init__(self, texts, vocab_size = 10000):\n",
    "        from collections import Counter\n",
    "        \n",
    "        self.vocab = {'<pad>': 0, '<unk>': 1}\n",
    "        words = Counter()\n",
    "        \n",
    "        for text in texts:\n",
    "            words.update(text.lower().split())\n",
    "        \n",
    "        for word, _ in words.most_common(vocab_size - 2):\n",
    "            self.vocab[word] = len(self.vocab)\n",
    "        \n",
    "        self.idx2word = {v: k for k, v in self.vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        return [self.vocab.get(w, 1) for w in text.lower().split()]\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        return ' '.join([self.idx2word.get(i, '<unk>') for i in ids if i > 0])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len=64):\n",
    "        self.data = []\n",
    "        for text in texts:\n",
    "            ids = tokenizer.encode(text)[:max_len]\n",
    "            if len(ids) > 1:\n",
    "                ids += [0] * (max_len - len(ids))\n",
    "                self.data.append(ids)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return torch.LongTensor(self.data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.g = nn.Parameter(torch.ones(dim))\n",
    "        self.b = nn.Parameter(torch.zeros(dim))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.g * (x - mean) / (std + self.eps) + self.b\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, n_heads):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.scale = (dim // n_heads) ** -0.5\n",
    "        self.qkv = nn.Linear(dim, dim * 3)\n",
    "        self.out = nn.Linear(dim, dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, T, 3, self.n_heads, C // self.n_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        \n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        mask = torch.tril(torch.ones(T, T, device=x.device)).view(1, 1, T, T)\n",
    "        attn = attn.masked_fill(mask == 0, float('-inf'))\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        \n",
    "        out = (attn @ v).transpose(1, 2).reshape(B, T, C)\n",
    "        return self.out(out)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, n_heads):\n",
    "        super().__init__()\n",
    "        self.ln1 = LayerNorm(dim)\n",
    "        self.ln2 = LayerNorm(dim)\n",
    "        self.attn = Attention(dim, n_heads)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, 4 * dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * dim, dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, dim=256, n_layers=4, n_heads=8, max_len=64):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, dim)\n",
    "        self.pos = nn.Parameter(torch.randn(1, max_len, dim))\n",
    "        self.blocks = nn.ModuleList([Block(dim, n_heads) for _ in range(n_layers)])\n",
    "        self.ln = LayerNorm(dim)\n",
    "        self.head = nn.Linear(dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x) + self.pos[:, :x.size(1)]\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.ln(x)\n",
    "        return self.head(x)\n",
    "    \n",
    "    def generate(self, idx, max_len=50):\n",
    "        for _ in range(max_len):\n",
    "            logits = self(idx[:, -64:])\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, 1)\n",
    "            idx = torch.cat([idx, idx_next], dim=1)\n",
    "            if idx_next.item() == 0:\n",
    "                break\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def train(model, loader, optimizer, device):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "    \n",
    "#     for batch in tqdm(loader):\n",
    "#         batch = batch.to(device)\n",
    "#         x, y = batch[:, :-1], batch[:, 1:]\n",
    "        \n",
    "#         logits = model(x)\n",
    "#         loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), y.reshape(-1), ignore_index = 0)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "        \n",
    "#     plt.plot(range(1, len(total_loss) + 1), total_loss, marker = 'o')\n",
    "#     plt.title('Training Loss per Epoch')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Average Training Loss')\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "#     return total_loss / len(loader)\n",
    "\n",
    "def train():\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # device = 'cpu'\n",
    "    \n",
    "    print(\"Loading TinyStories...\")\n",
    "    dataset = load_dataset(\"roneneldan/TinyStories\")\n",
    "    train_texts = [d['text'] for d in dataset['train'].select(range(10000))]\n",
    "    \n",
    "    print(\"Building tokenizer...\")\n",
    "    tokenizer = SimpleTokenizer(train_texts, vocab_size=10000)\n",
    "    print(f\"Vocab size: {len(tokenizer)}\")\n",
    "    \n",
    "    print(\"Loading FastText .bin...\")\n",
    "    ft_model = load_fasttext_bin(\"your_model.bin\")  # CHANGE THIS PATH\n",
    "    \n",
    "    sample_word = list(tokenizer.vocab.keys())[2]\n",
    "    sample_vec = get_embedding(ft_model, sample_word)\n",
    "    embed_dim = len(sample_vec) if sample_vec is not None else 256\n",
    "    print(f\"Embedding dim: {embed_dim}\")\n",
    "    \n",
    "    print(\"Creating dataset...\")\n",
    "    train_dataset = TextDataset(train_texts, tokenizer, max_len=64)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    print(\"Initializing model...\")\n",
    "    model = Transformer(\n",
    "        vocab_size=len(tokenizer),\n",
    "        dim=embed_dim,\n",
    "        n_layers=4,\n",
    "        n_heads=6,\n",
    "        max_len=64\n",
    "    ).to(device)\n",
    "    \n",
    "    print(\"Loading FastText embeddings...\")\n",
    "    with torch.no_grad():\n",
    "        for word, idx in tokenizer.vocab.items():\n",
    "            vec = get_embedding(ft_model, word)\n",
    "            if vec is not None:\n",
    "                model.embed.weight[idx] = torch.FloatTensor(vec)\n",
    "    \n",
    "    print(f\"Model params: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        print(f\"\\nEpoch {epoch + 1}\")\n",
    "        loss = train(model, train_loader, optimizer, device)\n",
    "        ppl = math.exp(loss)\n",
    "        print(f\"Loss: {loss:.4f}, PPL: {ppl:.2f}\")\n",
    "        \n",
    "        # Sample generation\n",
    "        prompt = torch.LongTensor([[tokenizer.vocab.get('once', 1)]]).to(device)\n",
    "        output = model.generate(prompt, max_len=30)\n",
    "        text = tokenizer.decode(output[0].tolist())\n",
    "        print(f\"Sample: {text}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), 'model.pt')\n",
    "    print(\"\\nModel saved!\")\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the little girl was curious who was so proud of the day. she wanted to invite her mom to wear. she said no. she tried to find something to make a pink dress for a <unk> so she put and couldn't wait to buy it. when she got very guilty. she knew she\n",
      "in the magical forest was very small and liked to play in the forest. she had a big bag of top. suddenly, she heard the sound of water and wondered what it was inside and had never been inside. she was so excited! she saw the <unk> molly showed out what she had never\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "\n",
    "def query_model(prompt = \"Once upon a time\", max_len = 100):    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    with open('tokenizer.pkl', 'rb') as f:\n",
    "        tok_data = pickle.load(f)\n",
    "    \n",
    "    class Tok:\n",
    "        def __init__(self, vocab, idx2word):\n",
    "            self.vocab = vocab\n",
    "            self.idx2word = idx2word\n",
    "        \n",
    "        def encode(self, text):\n",
    "            return [self.vocab.get(w, 1) for w in text.lower().split()]\n",
    "        \n",
    "        def decode(self, ids):\n",
    "            return ' '.join([self.idx2word.get(i, '<unk>') for i in ids if i > 0])\n",
    "    \n",
    "    tokenizer = Tok(tok_data['vocab'], tok_data['idx2word'])\n",
    "    model = Transformer(len(tokenizer.vocab), 300, 4, 6, 64).to(device)\n",
    "    model.load_state_dict(torch.load('model.pt', map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    x = torch.LongTensor([tokenizer.encode(prompt)]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            logits = model(x if x.size(1) <= 64 else x[:, -64:])\n",
    "            probs = F.softmax(logits[:, -1, :] / 0.8, dim=-1)\n",
    "            next_token = torch.multinomial(probs, 1)\n",
    "            if next_token.item() == 0:\n",
    "                break\n",
    "            x = torch.cat([x, next_token], dim=1)\n",
    "    \n",
    "    return tokenizer.decode(x[0].tolist())\n",
    "\n",
    "# print(query_model(\"Once upon a time\"))\n",
    "print(query_model(\"The little girl\"))\n",
    "print(query_model(\"In the magical forest\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on validation dataset, avg. Perplexity loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tok_data = pickle.load(f)\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self, vocab, idx2word):\n",
    "        self.vocab = vocab\n",
    "        self.idx2word = idx2word\n",
    "    \n",
    "    def encode(self, text):\n",
    "        return [self.vocab.get(w, 1) for w in text.lower().split()]\n",
    "\n",
    "tokenizer = Tokenizer(tok_data['vocab'], tok_data['idx2word'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len=64):\n",
    "        self.samples = []\n",
    "        \n",
    "        for text in texts:\n",
    "            ids = tokenizer.encode(text)\n",
    "            if len(ids) >= 2:  # Need at least 2 tokens\n",
    "                ids = ids[:max_len]\n",
    "                ids = ids + [0] * (max_len - len(ids))  # Pad\n",
    "                self.samples.append(ids)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.LongTensor(self.samples[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader for Val."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading validation data...\")\n",
    "val_data = load_dataset(\"roneneldan/TinyStories\", split = 'validation')\n",
    "val_texts = [item['text'] for item in val_data.select(range(1000))]\n",
    "\n",
    "print(\"Creating dataset...\")\n",
    "val_dataset = SimpleDataset(val_texts, tokenizer, max_len = 64)\n",
    "\n",
    "print(\"Creating dataloader...\")\n",
    "val_loader = DataLoader(val_dataset, batch_size = 32, shuffle = False)\n",
    "\n",
    "print(f\"Dataset size: {len(val_dataset)}\")\n",
    "\n",
    "# Test the loader\n",
    "print(\"\\nTesting loader...\")\n",
    "for batch in val_loader:\n",
    "    print(f\"Batch type: {type(batch)}\")\n",
    "    print(f\"Batch shape: {batch.shape}\")\n",
    "    print(\"✓ Loader works!\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "checkpoint = torch.load('model.pt', map_location='cpu')\n",
    "dim = checkpoint['pos'].shape[2]\n",
    "vocab_size = checkpoint['embed.weight'].shape[0]\n",
    "\n",
    "n_heads = 6\n",
    "\n",
    "print(f\"\\nModel: dim={dim}, n_heads={n_heads}, vocab={vocab_size}\")\n",
    "\n",
    "model = Transformer(vocab_size, dim, 4, n_heads, 64).to(device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data...\n",
      "Creating dataset...\n",
      "Creating dataloader...\n",
      "Dataset size: 1000\n",
      "\n",
      "Testing loader...\n",
      "Batch type: <class 'torch.Tensor'>\n",
      "Batch shape: torch.Size([32, 64])\n",
      "✓ Loader works!\n",
      "\n",
      "Model: dim=300, n_heads=6, vocab=10000\n",
      "✓ Model loaded\n",
      "\n",
      "Calculating perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 16.53it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Total tokens: 62957\n",
      "Average loss: 3.0630\n",
      "Perplexity: 21.39\n"
     ]
    }
   ],
   "source": [
    "def calculate_perplexity(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = []\n",
    "    sum_loss = 0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    print(\"\\nCalculating perplexity...\")\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            input_ids = batch[:, :-1]\n",
    "            target_ids = batch[:, 1:]\n",
    "            \n",
    "            logits = model(input_ids)\n",
    "            logits_flat = logits.reshape(-1, logits.size(-1))\n",
    "            target_flat = target_ids.reshape(-1)\n",
    "            \n",
    "            loss = F.cross_entropy(\n",
    "                logits_flat, \n",
    "                target_flat, \n",
    "                ignore_index = 0,\n",
    "                reduction='sum'\n",
    "            )\n",
    "            \n",
    "            num_tokens = (target_ids != 0).sum().item()\n",
    "            \n",
    "            total_loss.append(loss)\n",
    "            sum_loss += loss.item()\n",
    "            total_tokens += num_tokens\n",
    "            \n",
    "    plt.plot(range(1, len(total_loss)+1), total_loss, marker = 'o')\n",
    "    plt.title('pplxt')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('Perplexity per token')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # average loss and perplexity\n",
    "    avg_loss = sum_loss / total_tokens\n",
    "    perplexity = math.exp(avg_loss)\n",
    "    \n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"Total tokens: {total_tokens}\")\n",
    "    print(f\"Average loss: {avg_loss:.4f}\")\n",
    "    print(f\"Perplexity: {perplexity:.2f}\")\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "ppl = calculate_perplexity(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02d167e82c1e4500b7503ec3b74069f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0a05caf7b3364a3691f77307bab1847a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b7132da26cdb484b95ff01e4e024e65f",
       "style": "IPY_MODEL_902f4fcf9eaa4951ba6699c987859e29",
       "value": "Map: 100%"
      }
     },
     "0d0859fb9e804c0297931ff6be885743": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9f7b61c0e31c42759028bc264e5a58a4",
       "style": "IPY_MODEL_17c93af55bbb48b4ad239af5418e475b",
       "value": "Map:   9%"
      }
     },
     "106e27e9f2e043959156907f86434006": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_0d0859fb9e804c0297931ff6be885743",
        "IPY_MODEL_b3c4c6a802c341fe8e006024735c3d11",
        "IPY_MODEL_809f5bc8c7034a9b9e17bfeee78697c6"
       ],
       "layout": "IPY_MODEL_8212b484d1ba43dfac2b9ab5ab7b205a"
      }
     },
     "115f197770cc494e851dde9d105cac99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "17c93af55bbb48b4ad239af5418e475b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1b8f8de9d708458c989837c6b86658e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_fdb040ac7a754a88acc73e607466bcb8",
       "max": 2119719,
       "style": "IPY_MODEL_115f197770cc494e851dde9d105cac99",
       "value": 2119719
      }
     },
     "1faf09e6ab994885a3573e7fe4fe76d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2027d89c86df4f18aeaf0d04be596747": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_d30c7c74681247b4b1dc7188d100f6db",
       "max": 2119719,
       "style": "IPY_MODEL_4441617b66ee46ccac6c63293326551a",
       "value": 2119719
      }
     },
     "2092715d2f9a46f19b2bed9c97febf83": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2139f7e31090469d8dd8b4be4a7582a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2e0aea22593b458dac9a0a5286454f94",
       "style": "IPY_MODEL_e9dd82464e9343029389ca79c51cd78b",
       "value": "Map: 100%"
      }
     },
     "25230dc7526f44048a382f9b89bc3a03": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "26f81595cc584eb7b82976f34485f92b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f26acbe87ce0400bbf7afa3b75e43bf6",
       "style": "IPY_MODEL_51eb2d8cef1b409aba7b3ed0d81d7b1d",
       "value": "Map: 100%"
      }
     },
     "2a3a33208b974bab8fc3607506e6f710": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5cac6ea60cb84d6d94c0e9c4c3bc38ca",
       "style": "IPY_MODEL_f80c233ef38e45d3a658529713f49c9e",
       "value": "Map: 100%"
      }
     },
     "2c656064f79c4aeeb05036a2fc4796ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2cab67ed22bd4087a0ee83d5b7d88470": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_9b88f7e9b0a641e4aa94014a6d4e4cfc",
       "max": 21990,
       "style": "IPY_MODEL_7e253d7ffadb41fdb7daa2d6b1da8ea2",
       "value": 20920
      }
     },
     "2cc990189d7a43508dcdafbf6240bc3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c7362c8bfe3f457b85a2a115c1f28b2d",
       "style": "IPY_MODEL_3d78e4fd9c464406a515784aae0ba183",
       "value": " 2119719/2119719 [01:27&lt;00:00, 24567.03 examples/s]"
      }
     },
     "2de0ef8e27fe4932986d47006bb17321": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_2a3a33208b974bab8fc3607506e6f710",
        "IPY_MODEL_a291f9631aa84232933af9222d640b5d",
        "IPY_MODEL_be551ca5bc8143d6875953882faa058f"
       ],
       "layout": "IPY_MODEL_1faf09e6ab994885a3573e7fe4fe76d2"
      }
     },
     "2e0aea22593b458dac9a0a5286454f94": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "336ef1610a034257ae4dd20ca08d0869": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "33b75595888f43259609231d302a281d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "360a1c5638cb47bf993445c42a495b25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "36aa2dc5dfef48e48b9fa0ca967490de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e754b184430e4d51bd279c270ee6f0cb",
       "style": "IPY_MODEL_715717ac770048ab9121217e86174856",
       "value": " 21990/21990 [00:15&lt;00:00, 1346.62 examples/s]"
      }
     },
     "38a911e6589a4ca1bc30c8aad826f629": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_938c860da42d47b4a6c5f32942fea0f0",
       "max": 21990,
       "style": "IPY_MODEL_79b9126916c14351af68d0dd13b37afb",
       "value": 21990
      }
     },
     "397d54a2e34c4d1ebbe3c0b9faa33cff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3d78e4fd9c464406a515784aae0ba183": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "41a31b28b65b4701917e4b561d7b78a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4441617b66ee46ccac6c63293326551a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "479956541659456fae3078b97816f8b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "49c8a6782a4145edb289cce0018f377e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4aa176b5497848c5968fa330f3b668e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4ab833ac88cd46a6bd4f0169d1fca2cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "51eb2d8cef1b409aba7b3ed0d81d7b1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5207d1ffb34a47b39579c27a5eeda4d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5cac6ea60cb84d6d94c0e9c4c3bc38ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "61543f8d86e64942ac8151e11b4b0cfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_b1ea4eed079d4e9a9eeb112308e6c9b4",
        "IPY_MODEL_873344d4634a47c284b9298592d3ebe2",
        "IPY_MODEL_8e19a2c2bac84969ab4ffec59cce2544"
       ],
       "layout": "IPY_MODEL_be4d3a4749f94b81b51869927904eb6b"
      }
     },
     "6602d0d21eae43b6ac6230f73aa23ab5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "69b87377b5d1483b8d65cc7379546980": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_af481307515a4a2caae89e340f00279c",
        "IPY_MODEL_2cab67ed22bd4087a0ee83d5b7d88470",
        "IPY_MODEL_fb52aa5e8d7346caa46e0c1dcce597f1"
       ],
       "layout": "IPY_MODEL_81e1155e702b4611b6af8a8e7a877b07"
      }
     },
     "6c40775399ef4ea894659a7638468c81": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6d5f8ff2f9c348d6805efc4ed5c62548": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6d7780d7982c4524be4159388349772c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_26f81595cc584eb7b82976f34485f92b",
        "IPY_MODEL_2027d89c86df4f18aeaf0d04be596747",
        "IPY_MODEL_c10348153e8b4e5ebc85b201c7183cd4"
       ],
       "layout": "IPY_MODEL_9eaac96b74a346c3abd91603dbdd7d19"
      }
     },
     "715717ac770048ab9121217e86174856": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7544ec352b8c45418bfabb05a90ea0fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7789e8d170f94621b49d6721fcc9086c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "79b9126916c14351af68d0dd13b37afb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7e253d7ffadb41fdb7daa2d6b1da8ea2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7fb65e139bc24e2d8cd7325f579e4e31": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_e4531a1006324bdcba2791f90c5ad84a",
        "IPY_MODEL_a22895c5a7eb4bd3b2c6450670f196f6",
        "IPY_MODEL_a5f348e1870e4acfb8426e02178d725b"
       ],
       "layout": "IPY_MODEL_4aa176b5497848c5968fa330f3b668e6"
      }
     },
     "809f5bc8c7034a9b9e17bfeee78697c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c144f952d17d4b39a65567e7e9ee0d22",
       "style": "IPY_MODEL_ab03134bd51d438987ca1a75fb0e7157",
       "value": " 191240/2119719 [02:22&lt;25:45, 1247.85 examples/s]"
      }
     },
     "81e1155e702b4611b6af8a8e7a877b07": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8212b484d1ba43dfac2b9ab5ab7b205a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "873344d4634a47c284b9298592d3ebe2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_2c656064f79c4aeeb05036a2fc4796ae",
       "max": 2119719,
       "style": "IPY_MODEL_360a1c5638cb47bf993445c42a495b25",
       "value": 2119719
      }
     },
     "886ed95289fe4d05addb8097cfe92f95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8b4c86278ce347a99a2049e3f83eda43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8e19a2c2bac84969ab4ffec59cce2544": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b5e3b4b5aa1c48bd88f11c870ac4693b",
       "style": "IPY_MODEL_a4f271732df2483590b9d87e76f861c9",
       "value": " 2119719/2119719 [26:11&lt;00:00, 1188.65 examples/s]"
      }
     },
     "902f4fcf9eaa4951ba6699c987859e29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "938c860da42d47b4a6c5f32942fea0f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9578f1146be246ecb1c17c196c9f969d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9a83664ed89d47329dbbc94f4d81676a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9b88f7e9b0a641e4aa94014a6d4e4cfc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9c6eb3efffae4e8a82e458118332d4f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9eaac96b74a346c3abd91603dbdd7d19": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9f7b61c0e31c42759028bc264e5a58a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9f8e18fde4c94dc7b85ec0ceff4f75a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a22895c5a7eb4bd3b2c6450670f196f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_33b75595888f43259609231d302a281d",
       "max": 21990,
       "style": "IPY_MODEL_9f8e18fde4c94dc7b85ec0ceff4f75a1",
       "value": 21990
      }
     },
     "a291f9631aa84232933af9222d640b5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f8e8740774684ad7b2ab95631c1a454b",
       "max": 21990,
       "style": "IPY_MODEL_c7a900eaafa74190a368d04bedbf9d85",
       "value": 21990
      }
     },
     "a4f271732df2483590b9d87e76f861c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a5f348e1870e4acfb8426e02178d725b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_49c8a6782a4145edb289cce0018f377e",
       "style": "IPY_MODEL_7544ec352b8c45418bfabb05a90ea0fc",
       "value": " 21990/21990 [00:00&lt;00:00, 24864.50 examples/s]"
      }
     },
     "a7609ed0d05f45f69b838617571045d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e96e553e7ef34927adb05f288c9ea6e8",
       "style": "IPY_MODEL_6602d0d21eae43b6ac6230f73aa23ab5",
       "value": " 2119719/2119719 [02:22&lt;00:00, 15004.33 examples/s]"
      }
     },
     "ab03134bd51d438987ca1a75fb0e7157": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "af481307515a4a2caae89e340f00279c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fb7ccca7d55f46e38d34c446c08605bd",
       "style": "IPY_MODEL_479956541659456fae3078b97816f8b3",
       "value": "Map:  95%"
      }
     },
     "b01856f1ff7e46e0be65edbdf8f7c57b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_2139f7e31090469d8dd8b4be4a7582a4",
        "IPY_MODEL_1b8f8de9d708458c989837c6b86658e9",
        "IPY_MODEL_2cc990189d7a43508dcdafbf6240bc3a"
       ],
       "layout": "IPY_MODEL_6c40775399ef4ea894659a7638468c81"
      }
     },
     "b1ea4eed079d4e9a9eeb112308e6c9b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9a83664ed89d47329dbbc94f4d81676a",
       "style": "IPY_MODEL_d9d445b91b014b268224d7b1c8152ad1",
       "value": "Map: 100%"
      }
     },
     "b3c4c6a802c341fe8e006024735c3d11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_41a31b28b65b4701917e4b561d7b78a5",
       "max": 2119719,
       "style": "IPY_MODEL_6d5f8ff2f9c348d6805efc4ed5c62548",
       "value": 191240
      }
     },
     "b51668171bb24d9b8118976b8405334e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f99cdbf383cd42b4af408be316f9dc68",
        "IPY_MODEL_c8072df4654646d68051769686afd332",
        "IPY_MODEL_a7609ed0d05f45f69b838617571045d2"
       ],
       "layout": "IPY_MODEL_2092715d2f9a46f19b2bed9c97febf83"
      }
     },
     "b5379faae49b46ed9bbc2b7f76057460": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e5afdc1c325147cb89a1ce7d52e0b659",
       "style": "IPY_MODEL_d54b14ab266b4d8191f562c199031e99",
       "value": " 21990/21990 [00:01&lt;00:00, 18190.51 examples/s]"
      }
     },
     "b5e3b4b5aa1c48bd88f11c870ac4693b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b7132da26cdb484b95ff01e4e024e65f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ba9eef2110a841e7b137ff5911b83928": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f1102e805f704db4850e427cc04615f3",
        "IPY_MODEL_c7bf6815856e4a49b646c9af17e57bb4",
        "IPY_MODEL_36aa2dc5dfef48e48b9fa0ca967490de"
       ],
       "layout": "IPY_MODEL_f6b3cb48d2d14463ad5f5da97798ea9b"
      }
     },
     "be4d3a4749f94b81b51869927904eb6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "be551ca5bc8143d6875953882faa058f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f991d417f89e4b15aaf71ed40e6d178c",
       "style": "IPY_MODEL_02d167e82c1e4500b7503ec3b74069f2",
       "value": " 21990/21990 [01:36&lt;00:00, 490.57 examples/s]"
      }
     },
     "bf7b852452424614a0d0d9244413654c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c10348153e8b4e5ebc85b201c7183cd4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_bf7b852452424614a0d0d9244413654c",
       "style": "IPY_MODEL_8b4c86278ce347a99a2049e3f83eda43",
       "value": " 2119719/2119719 [01:56&lt;00:00, 17901.89 examples/s]"
      }
     },
     "c144f952d17d4b39a65567e7e9ee0d22": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c7362c8bfe3f457b85a2a115c1f28b2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c7a900eaafa74190a368d04bedbf9d85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c7bf6815856e4a49b646c9af17e57bb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e30bb9fae1eb4c618455732b71a51a46",
       "max": 21990,
       "style": "IPY_MODEL_9578f1146be246ecb1c17c196c9f969d",
       "value": 21990
      }
     },
     "c8072df4654646d68051769686afd332": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_886ed95289fe4d05addb8097cfe92f95",
       "max": 2119719,
       "style": "IPY_MODEL_ef1b7bbc159f4b20a2853162924f4c9e",
       "value": 2119719
      }
     },
     "cd36a26d1ded4f77881f6618a767ca89": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cf47cdc9a7384061a448572ca914ca41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_0a05caf7b3364a3691f77307bab1847a",
        "IPY_MODEL_38a911e6589a4ca1bc30c8aad826f629",
        "IPY_MODEL_b5379faae49b46ed9bbc2b7f76057460"
       ],
       "layout": "IPY_MODEL_336ef1610a034257ae4dd20ca08d0869"
      }
     },
     "d30c7c74681247b4b1dc7188d100f6db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d54b14ab266b4d8191f562c199031e99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d9d445b91b014b268224d7b1c8152ad1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e30bb9fae1eb4c618455732b71a51a46": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e4531a1006324bdcba2791f90c5ad84a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_25230dc7526f44048a382f9b89bc3a03",
       "style": "IPY_MODEL_4ab833ac88cd46a6bd4f0169d1fca2cc",
       "value": "Map: 100%"
      }
     },
     "e5afdc1c325147cb89a1ce7d52e0b659": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e754b184430e4d51bd279c270ee6f0cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e96e553e7ef34927adb05f288c9ea6e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e9dd82464e9343029389ca79c51cd78b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ef1b7bbc159f4b20a2853162924f4c9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "efa16afb7caa48f2938e03de5f964cf4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f1102e805f704db4850e427cc04615f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_efa16afb7caa48f2938e03de5f964cf4",
       "style": "IPY_MODEL_397d54a2e34c4d1ebbe3c0b9faa33cff",
       "value": "Map: 100%"
      }
     },
     "f26acbe87ce0400bbf7afa3b75e43bf6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f6b3cb48d2d14463ad5f5da97798ea9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f80c233ef38e45d3a658529713f49c9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f8e8740774684ad7b2ab95631c1a454b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f991d417f89e4b15aaf71ed40e6d178c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f99cdbf383cd42b4af408be316f9dc68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5207d1ffb34a47b39579c27a5eeda4d3",
       "style": "IPY_MODEL_9c6eb3efffae4e8a82e458118332d4f9",
       "value": "Map: 100%"
      }
     },
     "fb52aa5e8d7346caa46e0c1dcce597f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_cd36a26d1ded4f77881f6618a767ca89",
       "style": "IPY_MODEL_7789e8d170f94621b49d6721fcc9086c",
       "value": " 20920/21990 [00:15&lt;00:00, 1360.96 examples/s]"
      }
     },
     "fb7ccca7d55f46e38d34c446c08605bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fdb040ac7a754a88acc73e607466bcb8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
